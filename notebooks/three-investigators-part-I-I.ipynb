{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Three investigators - part I.I\n",
    "\n",
    "A project for scraping and analysing data from a fan site on the audio book called '[The three investigators](https://en.wikipedia.org/wiki/Three_Investigators#Germany)'\n",
    "\n",
    "Part I.I: Topic modelling\n",
    "\n",
    "Using the content and title for each episode to detect the overall topic.\n",
    "\n",
    "\n",
    "**Resources:** \n",
    "\n",
    "- Text mining webinar code on [github](https://github.com/DiarmuidM/text-mining/blob/master/code/tm-extraction-2020-06-16.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.7.5\n"
     ]
    }
   ],
   "source": [
    "#python version used for this project\n",
    "from platform import python_version\n",
    "print(python_version())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> need to add additional modules to requirement text file !!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import modules [as specified in requirements.txt]\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spacy\n",
    "import de_core_news_sm #imports German model from spaCy\n",
    "import nltk\n",
    "import re\n",
    "\n",
    "# download German stop words\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('german'))\n",
    "\n",
    "# To count words in list\n",
    "from collections import Counter\n",
    "\n",
    "# for file \n",
    "import os\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#change directory to root folder\n",
    "os.chdir(\"..\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load scraped datafiles\n",
    "meta = pd.read_csv(\".\\\\data\\\\scraped\\\\meta.csv\")\n",
    "content = pd.read_csv(\".\\\\data\\\\scraped\\\\content_all.csv\")\n",
    "\n",
    "# make all column names lower case\n",
    "df_list = [meta, content]\n",
    "\n",
    "for df in df_list:\n",
    "    df.columns = df.columns.str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Title"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standardising"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0            Der Super-Papagei (Hörspiel)\n",
       "1               Der Phantomsee (Hörspiel)\n",
       "2             Der Karpatenhund (Hörspiel)\n",
       "3           Die schwarze Katze (Hörspiel)\n",
       "4         Der Fluch des Rubins (Hörspiel)\n",
       "                      ...                \n",
       "200             Das weiße Grab (Hörspiel)\n",
       "201    Tauchgang ins Ungewisse (Hörspiel)\n",
       "202         Der dunkle Wächter (Hörspiel)\n",
       "203       Das rätselhafte Erbe (Hörspiel)\n",
       "204      ...und der Mottenmann (Hörspiel)\n",
       "Name: titel, Length: 205, dtype: object"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta[\"titel\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0             der superpapagei\n",
       "1               der phantomsee\n",
       "2             der karpatenhund\n",
       "3           die schwarze katze\n",
       "4          der fluch des rubin\n",
       "                ...           \n",
       "200             das weiße grab\n",
       "201    tauchgang ins ungewisse\n",
       "202         der dunkle wächter\n",
       "203       das rätselhafte erbe\n",
       "204         und der mottenmann\n",
       "Name: titel, Length: 205, dtype: object"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## make titles lower case\n",
    "title = meta[\"titel\"].str.lower()\n",
    "\n",
    "# replace values within titles\n",
    "\n",
    "# function to loop through the column and replace substrings\n",
    "def replace_values(text, dic):\n",
    "    for x, y in dic.items():\n",
    "        text = text.str.replace(x, y, regex=True)\n",
    "    return text\n",
    "\n",
    "# list of values to be replaced, including punctuation\n",
    "replace_dict = {\"hörspiel\": \"\", \n",
    "                \"[!\\\"#$%&()*+,./:;<=>?@[\\]^_`{|}~“”-]\": \"\",\n",
    "                \n",
    "                #list of noun forms that the German lemmitizer doesn't pick up\n",
    "                \"tigers\": \"tiger\",\n",
    "                \"fouls\":\"foul\",\n",
    "                \"teufels\":\"teufel\",\n",
    "                \"schreckens\":\"schrecken\",\n",
    "                \"meisterdiebs\":\"meisterdieb\",\n",
    "                \"grauens\":\"grauen\",\n",
    "                \"todes\":\"tod\",\n",
    "                \"spielers\":\"spieler\",\n",
    "                u\"goldgräbers\" :u\"goldgräber\"  ,\n",
    "                \"zauberers\":\"zauberer\",\n",
    "                \"henkers\":\"henker\",\n",
    "                \"vergessens\" :\"vergessen\",\n",
    "                \"bauchredners\" :\"bauchredner\",\n",
    "                \"sturms\" : \"sturm\",\n",
    "                \"rubins\":\"rubin\",\n",
    "               \n",
    "                #change plural to singular and remove gendered forms\n",
    "                \"musikpiraten\" : \"musikpirat\",\n",
    "                \"seglerin\" : \"segler\",\n",
    "                \"stimmen\" : \"stimme\",\n",
    "                \"karten\":\"karte\",\n",
    "                u\"dämonen\": u\"dämon\",\n",
    "                \"drachen\":\"drache\",\n",
    "                \"piraten\":\"pirat\",\n",
    "                \"botschaften\": \"botschaft\",\n",
    "                \"raben\":\"rabe\",\n",
    "                \"schlangen\":\"schlange\",\n",
    "                \"untoten\":\"untote\",\n",
    "                \"puppen\":\"puppe\",\n",
    "                \"augen\" : \"auge\",\n",
    "                \"vampire\":\"vampir\"               }\n",
    "                \n",
    "# apply function\n",
    "title = replace_values(title, replace_dict)\n",
    "\n",
    "# strip white space at the end\n",
    "title = title.str.strip()\n",
    "\n",
    "title"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### remove stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['superpapagei',\n",
       " 'phantomsee',\n",
       " 'karpatenhund',\n",
       " 'schwarze katze',\n",
       " 'fluch rubin',\n",
       " 'sprechende totenkopf',\n",
       " 'unheimliche drache',\n",
       " 'grüne geist',\n",
       " 'rätselhaften bilder',\n",
       " 'flüsternde mumie']"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# split titles into substrings using space as delimiter\n",
    "title_split = title.str.split(\" \")\n",
    "\n",
    "# create empty list to store titles without stop words\n",
    "title_no_stop_words = []\n",
    "\n",
    "# iterate through each word in each title and append those that are no stop words\n",
    "for words in title_split:\n",
    "    x = []\n",
    "    for word in words:\n",
    "        if word not in stop_words:\n",
    "            x.append(word)\n",
    "    title_no_stop_words.append(x)\n",
    "\n",
    "# join titles back together\n",
    "title_no_stop_words = [\" \".join(items) for items in title_no_stop_words]\n",
    "title_no_stop_words[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### lemmatise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['superpapagei',\n",
       " 'phantomsee',\n",
       " 'karpatenhund',\n",
       " 'schwarze',\n",
       " 'katze',\n",
       " 'fluch',\n",
       " 'rubin',\n",
       " 'sprechend',\n",
       " 'totenkopf',\n",
       " 'unheimlich']"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## merge titles into one string\n",
    "titles_one_string =  ' '.join(title_no_stop_words)\n",
    "\n",
    "# load German model from SpaCy\n",
    "nlp = de_core_news_sm.load()\n",
    "\n",
    "# create new list to store lemmatised titles\n",
    "titles_lemmatised = []\n",
    "\n",
    "# iterate through titles as one string and store the lemmatised words in new list\n",
    "for title in nlp(titles_one_string):\n",
    "    x = title.lemma_\n",
    "    titles_lemmatised.append(x)\n",
    "\n",
    "titles_lemmatised[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized: superpapagei | Lemma: superpapagei\n",
      "Tokenized: phantomsee | Lemma: phantomsee\n",
      "Tokenized: karpatenhund | Lemma: karpatenhund\n",
      "Tokenized: schwarze | Lemma: schwarze\n",
      "Tokenized: katze | Lemma: katze\n",
      "Tokenized: fluch | Lemma: fluch\n",
      "Tokenized: rubin | Lemma: rubin\n",
      "Tokenized: sprechende | Lemma: sprechend\n",
      "Tokenized: totenkopf | Lemma: totenkopf\n",
      "Tokenized: unheimliche | Lemma: unheimlich\n",
      "Tokenized: drache | Lemma: drache\n",
      "Tokenized: grüne | Lemma: grüne\n",
      "Tokenized: geist | Lemma: geist\n",
      "Tokenized: rätselhaften | Lemma: rätselhaft\n",
      "Tokenized: bilder | Lemma: bilder\n",
      "Tokenized: flüsternde | Lemma: flüsternd\n",
      "Tokenized: mumie | Lemma: mumie\n",
      "Tokenized: gespensterschloß | Lemma: gespensterschloß\n",
      "Tokenized: seltsame | Lemma: seltsam\n",
      "Tokenized: wecker | Lemma: wecker\n",
      "Tokenized: lachende | Lemma: lachend\n",
      "Tokenized: schatten | Lemma: schatten\n",
      "Tokenized: bergmonster | Lemma: bergmonster\n",
      "Tokenized: rasende | Lemma: rasend\n",
      "Tokenized: löwe | Lemma: löwe\n",
      "Tokenized: zauberspiegel | Lemma: zauberspiegel\n",
      "Tokenized: gefährliche | Lemma: gefährlich\n",
      "Tokenized: erbschaft | Lemma: erbschaft\n",
      "Tokenized: geisterinsel | Lemma: geisterinsel\n",
      "Tokenized: teufelberg | Lemma: teufelberg\n",
      "Tokenized: flammende | Lemma: flammend\n",
      "Tokenized: spur | Lemma: spur\n",
      "Tokenized: tanzende | Lemma: tanzend\n",
      "Tokenized: teufel | Lemma: teufel\n",
      "Tokenized: verschwundene | Lemma: verschwunden\n",
      "Tokenized: schatz | Lemma: schatz\n",
      "Tokenized: aztekenschwert | Lemma: aztekenschwert\n",
      "Tokenized: silberne | Lemma: silberne\n",
      "Tokenized: spinne | Lemma: spinne\n",
      "Tokenized: singende | Lemma: singend\n",
      "Tokenized: schlange | Lemma: schlange\n",
      "Tokenized: silbermine | Lemma: silbermine\n",
      "Tokenized: magische | Lemma: magische\n",
      "Tokenized: kreis | Lemma: kreis\n",
      "Tokenized: doppelgänger | Lemma: doppelgänger\n",
      "Tokenized: riff | Lemma: riff\n",
      "Tokenized: haie | Lemma: haie\n",
      "Tokenized: narbengesicht | Lemma: narbengesicht\n",
      "Tokenized: ameisenmensch | Lemma: ameisenmensch\n",
      "Tokenized: bedrohte | Lemma: bedrohen\n",
      "Tokenized: ranch | Lemma: ranch\n",
      "Tokenized: rote | Lemma: rote\n",
      "Tokenized: pirat | Lemma: pirat\n",
      "Tokenized: höhlenmensch | Lemma: höhlenmensch\n",
      "Tokenized: superwal | Lemma: superwal\n",
      "Tokenized: heimliche | Lemma: heimlich\n",
      "Tokenized: hehler | Lemma: hehler\n",
      "Tokenized: unsichtbare | Lemma: unsichtbar\n",
      "Tokenized: gegner | Lemma: gegner\n",
      "Tokenized: perlenvögel | Lemma: perlenvögel\n",
      "Tokenized: automarder | Lemma: automarder\n",
      "Tokenized: volk | Lemma: volk\n",
      "Tokenized: winde | Lemma: winde\n",
      "Tokenized: weinende | Lemma: weinend\n",
      "Tokenized: sarg | Lemma: sarg\n",
      "Tokenized: höllische | Lemma: höllische\n",
      "Tokenized: werwolf | Lemma: werwolf\n",
      "Tokenized: gestohlene | Lemma: gestohlen\n",
      "Tokenized: preis | Lemma: preis\n",
      "Tokenized: gold | Lemma: gold\n",
      "Tokenized: wikinger | Lemma: wikinger\n",
      "Tokenized: schrullige | Lemma: schrullig\n",
      "Tokenized: millionär | Lemma: millionär\n",
      "Tokenized: giftige | Lemma: giftig\n",
      "Tokenized: gockel | Lemma: gockel\n",
      "Tokenized: gefährlichen | Lemma: gefährlich\n",
      "Tokenized: fässer | Lemma: fässer\n",
      "Tokenized: comicdiebe | Lemma: comicdiebe\n",
      "Tokenized: verschwundene | Lemma: verschwunden\n",
      "Tokenized: filmstar | Lemma: filmstar\n",
      "Tokenized: riskante | Lemma: riskante\n",
      "Tokenized: ritt | Lemma: ritt\n",
      "Tokenized: musikpirat | Lemma: musikpirat\n",
      "Tokenized: automafia | Lemma: automafia\n",
      "Tokenized: gefahr | Lemma: gefahr\n",
      "Tokenized: verzug | Lemma: verzug\n",
      "Tokenized: gekaufte | Lemma: gekauft\n",
      "Tokenized: spieler | Lemma: spieler\n",
      "Tokenized: angriff | Lemma: angreifen\n",
      "Tokenized: computerviren | Lemma: computerviren\n",
      "Tokenized: tatort | Lemma: tatort\n",
      "Tokenized: zirkus | Lemma: zirkus\n",
      "Tokenized: verrückte | Lemma: verrücken\n",
      "Tokenized: maler | Lemma: maler\n",
      "Tokenized: giftiges | Lemma: giftig\n",
      "Tokenized: wasser | Lemma: wasser\n",
      "Tokenized: dopingmixer | Lemma: dopingmixer\n",
      "Tokenized: rache | Lemma: rache\n",
      "Tokenized: tiger | Lemma: tiger\n",
      "Tokenized: spuk | Lemma: spuk\n",
      "Tokenized: hotel | Lemma: hotel\n",
      "Tokenized: fußballgangster | Lemma: fußballgangster\n",
      "Tokenized: geisterstadt | Lemma: geisterstadt\n",
      "Tokenized: diamantenschmuggel | Lemma: diamantenschmuggel\n",
      "Tokenized: schattenmänner | Lemma: schattenmänner\n",
      "Tokenized: geheimnis | Lemma: geheimnis\n",
      "Tokenized: särge | Lemma: särge\n",
      "Tokenized: schatz | Lemma: schatz\n",
      "Tokenized: bergsee | Lemma: bergsee\n",
      "Tokenized: späte | Lemma: spät\n",
      "Tokenized: rache | Lemma: rache\n",
      "Tokenized: schüsse | Lemma: schüsse\n",
      "Tokenized: dunkel | Lemma: dunkeln\n",
      "Tokenized: verschwundene | Lemma: verschwunden\n",
      "Tokenized: segler | Lemma: segler\n",
      "Tokenized: dreckiger | Lemma: dreckig\n",
      "Tokenized: deal | Lemma: deal\n",
      "Tokenized: poltergeist | Lemma: poltergeist\n",
      "Tokenized: brennende | Lemma: brennend\n",
      "Tokenized: schwert | Lemma: schwert\n",
      "Tokenized: spur | Lemma: spur\n",
      "Tokenized: rabe | Lemma: rabe\n",
      "Tokenized: stimme | Lemma: stimme\n",
      "Tokenized: pistenteufel | Lemma: pistenteufel\n",
      "Tokenized: leere | Lemma: leer\n",
      "Tokenized: grab | Lemma: grab\n",
      "Tokenized: bann | Lemma: bann\n",
      "Tokenized: voodoo | Lemma: voodoo\n",
      "Tokenized: geheimakte | Lemma: geheimakte\n",
      "Tokenized: ufo | Lemma: ufo\n",
      "Tokenized: verdeckte | Lemma: verdecken\n",
      "Tokenized: foul | Lemma: foul\n",
      "Tokenized: karte | Lemma: karte\n",
      "Tokenized: bösen | Lemma: böse\n",
      "Tokenized: meuterei | Lemma: meuterei\n",
      "Tokenized: hoher | Lemma: hoch\n",
      "Tokenized: see | Lemma: see\n",
      "Tokenized: musik | Lemma: musik\n",
      "Tokenized: teufel | Lemma: teufel\n",
      "Tokenized: feuerturm | Lemma: feuerturm\n",
      "Tokenized: nacht | Lemma: nacht\n",
      "Tokenized: angst | Lemma: angst\n",
      "Tokenized: wolfsgesicht | Lemma: wolfsgesicht\n",
      "Tokenized: vampir | Lemma: vampir\n",
      "Tokenized: internet | Lemma: internet\n",
      "Tokenized: tödliche | Lemma: tödlich\n",
      "Tokenized: spur | Lemma: spur\n",
      "Tokenized: feuerteufel | Lemma: feuerteufel\n",
      "Tokenized: labyrinth | Lemma: labyrinth\n",
      "Tokenized: götter | Lemma: götter\n",
      "Tokenized: todflug | Lemma: todflug\n",
      "Tokenized: geisterschiff | Lemma: geisterschiff\n",
      "Tokenized: schwarze | Lemma: schwarze\n",
      "Tokenized: monster | Lemma: monster\n",
      "Tokenized: botschaft | Lemma: botschaft\n",
      "Tokenized: geisterhand | Lemma: geisterhand\n",
      "Tokenized: rote | Lemma: rote\n",
      "Tokenized: rächer | Lemma: rächer\n",
      "Tokenized: insektenstachel | Lemma: insektenstachel\n",
      "Tokenized: tal | Lemma: tal\n",
      "Tokenized: schrecken | Lemma: schrecken\n",
      "Tokenized: rufmord | Lemma: rufmord\n",
      "Tokenized: toteninsel | Lemma: toteninsel\n",
      "Tokenized: hexenhandy | Lemma: hexenhandy\n",
      "Tokenized: doppelte | Lemma: doppeln\n",
      "Tokenized: täuschung | Lemma: täuschung\n",
      "Tokenized: erbe | Lemma: erben\n",
      "Tokenized: meisterdieb | Lemma: meisterdieb\n",
      "Tokenized: gift | Lemma: gift\n",
      "Tokenized: per | Lemma: per\n",
      "Tokenized: email | Lemma: email\n",
      "Tokenized: nebelberg | Lemma: nebelberg\n",
      "Tokenized: mann | Lemma: mann\n",
      "Tokenized: kopf | Lemma: kopf\n",
      "Tokenized: schatz | Lemma: schatz\n",
      "Tokenized: mönche | Lemma: mönche\n",
      "Tokenized: sieben | Lemma: sieben\n",
      "Tokenized: tore | Lemma: tore\n",
      "Tokenized: gefährliches | Lemma: gefährlich\n",
      "Tokenized: quiz | Lemma: quiz\n",
      "Tokenized: panik | Lemma: panik\n",
      "Tokenized: park | Lemma: park\n",
      "Tokenized: höhle | Lemma: höhle\n",
      "Tokenized: grauen | Lemma: grau\n",
      "Tokenized: schlucht | Lemma: schlucht\n",
      "Tokenized: dämon | Lemma: dämon\n",
      "Tokenized: auge | Lemma: auge\n",
      "Tokenized: drache | Lemma: drache\n",
      "Tokenized: villa | Lemma: villa\n",
      "Tokenized: toten | Lemma: tot\n",
      "Tokenized: tödlichem | Lemma: tödlich\n",
      "Tokenized: kurs | Lemma: kurs\n",
      "Tokenized: codename | Lemma: codename\n",
      "Tokenized: cobra | Lemma: cobra\n",
      "Tokenized: finstere | Lemma: finstere\n",
      "Tokenized: rivale | Lemma: rivale\n",
      "Tokenized: düstere | Lemma: düster\n",
      "Tokenized: vermächtnis | Lemma: vermächtnis\n",
      "Tokenized: geheime | Lemma: geheime\n",
      "Tokenized: schlüssel | Lemma: schlüssel\n",
      "Tokenized: schwarze | Lemma: schwarze\n",
      "Tokenized: skorpion | Lemma: skorpion\n",
      "Tokenized: spur | Lemma: spur\n",
      "Tokenized: geisterzug | Lemma: geisterzug\n",
      "Tokenized: fußballfieber | Lemma: fußballfieber\n",
      "Tokenized: geistercanyon | Lemma: geistercanyon\n",
      "Tokenized: feuermond | Lemma: feuermond\n",
      "Tokenized: schrecken | Lemma: schrecken\n",
      "Tokenized: moor | Lemma: moor\n",
      "Tokenized: schwarze | Lemma: schwarze\n",
      "Tokenized: madonna | Lemma: madonna\n",
      "Tokenized: schatten | Lemma: schatten\n",
      "Tokenized: hollywood | Lemma: hollywood\n",
      "Tokenized: sms | Lemma: sms\n",
      "Tokenized: grab | Lemma: grab\n",
      "Tokenized: fluch | Lemma: fluch\n",
      "Tokenized: drache | Lemma: drache\n",
      "Tokenized: haus | Lemma: haus\n",
      "Tokenized: schrecken | Lemma: schrecken\n",
      "Tokenized: spuk | Lemma: spuk\n",
      "Tokenized: netz | Lemma: netz\n",
      "Tokenized: fels | Lemma: fels\n",
      "Tokenized: dämon | Lemma: dämon\n",
      "Tokenized: tote | Lemma: tot\n",
      "Tokenized: mönch | Lemma: mönch\n",
      "Tokenized: fluch | Lemma: fluch\n",
      "Tokenized: pirat | Lemma: pirat\n",
      "Tokenized: versunkene | Lemma: versunken\n",
      "Tokenized: dorf | Lemma: dorf\n",
      "Tokenized: pfad | Lemma: pfad\n",
      "Tokenized: angst | Lemma: angst\n",
      "Tokenized: geheime | Lemma: geheime\n",
      "Tokenized: treppe | Lemma: treppe\n",
      "Tokenized: geheimnis | Lemma: geheimnis\n",
      "Tokenized: diva | Lemma: diva\n",
      "Tokenized: stadt | Lemma: stadt\n",
      "Tokenized: vampir | Lemma: vampir\n",
      "Tokenized: fußballfalle | Lemma: fußballfalle\n",
      "Tokenized: tödliches | Lemma: tödlich\n",
      "Tokenized: eis | Lemma: eis\n",
      "Tokenized: poker | Lemma: poker\n",
      "Tokenized: hölle | Lemma: hölle\n",
      "Tokenized: zwillinge | Lemma: zwillinge\n",
      "Tokenized: finsternis | Lemma: finsternis\n",
      "Tokenized: rache | Lemma: rache\n",
      "Tokenized: samurai | Lemma: samurai\n",
      "Tokenized: biss | Lemma: biss\n",
      "Tokenized: bestie | Lemma: bestie\n",
      "Tokenized: grusel | Lemma: grusel\n",
      "Tokenized: campbell | Lemma: campbell\n",
      "Tokenized: castle | Lemma: castle\n",
      "Tokenized: feurige | Lemma: feurige\n",
      "Tokenized: flut | Lemma: flut\n",
      "Tokenized: namenlose | Lemma: namenlose\n",
      "Tokenized: gegner | Lemma: gegner\n",
      "Tokenized: geisterbucht | Lemma: geisterbucht\n",
      "Tokenized: schwarze | Lemma: schwarze\n",
      "Tokenized: sonne | Lemma: sonne\n",
      "Tokenized: skateboardfieber | Lemma: skateboardfieber\n",
      "Tokenized: fußballphantom | Lemma: fußballphantom\n",
      "Tokenized: botschaft | Lemma: botschaft\n",
      "Tokenized: unterwelt | Lemma: unterwelt\n",
      "Tokenized: meister | Lemma: meistern\n",
      "Tokenized: tod | Lemma: tod\n",
      "Tokenized: netz | Lemma: netz\n",
      "Tokenized: drache | Lemma: drache\n",
      "Tokenized: zeichen | Lemma: zeichen\n",
      "Tokenized: schlange | Lemma: schlange\n",
      "Tokenized: feuergeist | Lemma: feuergeist\n",
      "Tokenized: nacht | Lemma: nacht\n",
      "Tokenized: tiger | Lemma: tiger\n",
      "Tokenized: geheimnisvolle | Lemma: geheimnisvolle\n",
      "Tokenized: botschaft | Lemma: botschaft\n",
      "Tokenized: blutenden | Lemma: blutend\n",
      "Tokenized: bilder | Lemma: bilder\n",
      "Tokenized: schreiende | Lemma: schreiend\n",
      "Tokenized: nebel | Lemma: nebel\n",
      "Tokenized: verschollene | Lemma: verschollen\n",
      "Tokenized: pilot | Lemma: pilot\n",
      "Tokenized: fußballteufel | Lemma: fußballteufel\n",
      "Tokenized: schatten | Lemma: schatten\n",
      "Tokenized: giganten | Lemma: giganten\n",
      "Tokenized: brennende | Lemma: brennend\n",
      "Tokenized: stadt | Lemma: stadt\n",
      "Tokenized: blaue | Lemma: blau\n",
      "Tokenized: biest | Lemma: biest\n",
      "Tokenized: gps | Lemma: gps\n",
      "Tokenized:   | Lemma:  \n",
      "Tokenized: gangster | Lemma: gangster\n",
      "Tokenized: spur | Lemma: spur\n",
      "Tokenized: spieler | Lemma: spieler\n",
      "Tokenized: straße | Lemma: straße\n",
      "Tokenized: grauen | Lemma: grau\n",
      "Tokenized: phantom | Lemma: phantom\n",
      "Tokenized: meer | Lemma: meer\n",
      "Tokenized: eisenmann | Lemma: eisenmann\n",
      "Tokenized: dämon | Lemma: dämon\n",
      "Tokenized: rache | Lemma: rache\n",
      "Tokenized: tuch | Lemma: tuch\n",
      "Tokenized: toten | Lemma: tot\n",
      "Tokenized: schattenwelt | Lemma: schattenwelt\n",
      "Tokenized: gestohlene | Lemma: gestohlen\n",
      "Tokenized: sieg | Lemma: sieg\n",
      "Tokenized: geist | Lemma: geist\n",
      "Tokenized: goldgräber | Lemma: goldgräber\n",
      "Tokenized: gefiederte | Lemma: gefiedert\n",
      "Tokenized: schrecken | Lemma: schrecken\n",
      "Tokenized: rache | Lemma: rache\n",
      "Tokenized: untote | Lemma: untote\n",
      "Tokenized: flüsternden | Lemma: flüsternd\n",
      "Tokenized: puppe | Lemma: puppe\n",
      "Tokenized: kabinett | Lemma: kabinett\n",
      "Tokenized: zauberer | Lemma: zauberer\n",
      "Tokenized: haus | Lemma: haus\n",
      "Tokenized: henker | Lemma: henker\n",
      "Tokenized: letzte | Lemma: letzte\n",
      "Tokenized: song | Lemma: song\n",
      "Tokenized: hexengarten | Lemma: hexengarten\n",
      "Tokenized: mann | Lemma: mann\n",
      "Tokenized: auge | Lemma: auge\n",
      "Tokenized: insel | Lemma: insel\n",
      "Tokenized: vergessen | Lemma: vergessen\n",
      "Tokenized: silberne | Lemma: silberne\n",
      "Tokenized: amulett | Lemma: amulett\n",
      "Tokenized: signale | Lemma: signale\n",
      "Tokenized: jenseits | Lemma: jenseits\n",
      "Tokenized: unsichtbare | Lemma: unsichtbar\n",
      "Tokenized: passagier | Lemma: passagier\n",
      "Tokenized: kammer | Lemma: kammer\n",
      "Tokenized: rätsel | Lemma: rätsel\n",
      "Tokenized: verbrechen | Lemma: verbrechen\n",
      "Tokenized: bann | Lemma: bann\n",
      "Tokenized: drache | Lemma: drache\n",
      "Tokenized: schrecken | Lemma: schrecken\n",
      "Tokenized: tiefe | Lemma: tiefe\n",
      "Tokenized: zeitreisende | Lemma: zeitreisende\n",
      "Tokenized: reich | Lemma: reichen\n",
      "Tokenized: ungeheuer | Lemma: ungeheuer\n",
      "Tokenized: geheimnis | Lemma: geheimnis\n",
      "Tokenized: bauchredner | Lemma: bauchredner\n",
      "Tokenized: auge | Lemma: auge\n",
      "Tokenized: sturm | Lemma: sturm\n",
      "Tokenized: legende | Lemma: legend\n",
      "Tokenized: gaukler | Lemma: gaukler\n",
      "Tokenized: grüne | Lemma: grüne\n",
      "Tokenized: kobold | Lemma: kobold\n",
      "Tokenized: feuriges | Lemma: feurig\n",
      "Tokenized: auge | Lemma: auge\n",
      "Tokenized: höhenangst | Lemma: höhenangst\n",
      "Tokenized: weiße | Lemma: weiße\n",
      "Tokenized: grab | Lemma: grab\n",
      "Tokenized: tauchgang | Lemma: tauchgang\n",
      "Tokenized: ungewisse | Lemma: ungewiß\n",
      "Tokenized: dunkle | Lemma: dunkel\n",
      "Tokenized: wächter | Lemma: wächter\n",
      "Tokenized: rätselhafte | Lemma: rätselhaft\n",
      "Tokenized: erbe | Lemma: erben\n",
      "Tokenized: mottenmann | Lemma: mottenmann\n"
     ]
    }
   ],
   "source": [
    "## Check how words have been lemmatised to explore potential issues\n",
    "words = str(titles_one_string)\n",
    "\n",
    "for word in nlp.tokenizer(words):\n",
    "    print(\"Tokenized: %s | Lemma: %s\" %(word, word.lemma_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Counting words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>spur</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>rache</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>schwarze</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>drache</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>schrecken</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>stimme</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>pistenteufel</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>leer</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>voodoo</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283</th>\n",
       "      <td>mottenmann</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>284 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            index  0\n",
       "31           spur  5\n",
       "94          rache  5\n",
       "3        schwarze  5\n",
       "10         drache  5\n",
       "149     schrecken  5\n",
       "..            ... ..\n",
       "115        stimme  1\n",
       "116  pistenteufel  1\n",
       "117          leer  1\n",
       "120        voodoo  1\n",
       "283    mottenmann  1\n",
       "\n",
       "[284 rows x 2 columns]"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# count frequencies of words\n",
    "counts = Counter(titles_lemmatised)\n",
    "counts = pd.DataFrame.from_dict(counts, orient='index').reset_index() #make into dataframe\n",
    "counts = counts.sort_values(by=counts.columns[1], ascending=False) #sort by frequency\n",
    "counts.to_csv(\"test.csv\")\n",
    "counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "# groups of words\n",
    "colours = [r'grüne*[nsr]*$' , r'^schw[aä]rze*[nsr]*$']\n",
    "\n",
    "\n",
    "for i in colours:\n",
    "    if i in titles_lemmatised:\n",
    "        print(\"yes\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['superpapagei',\n",
       " 'phantomsee',\n",
       " 'karpatenhund',\n",
       " 'schwarze katze',\n",
       " 'fluch rubin',\n",
       " 'sprechende totenkopf',\n",
       " 'unheimliche drache',\n",
       " 'grüne geist',\n",
       " 'rätselhaften bilder',\n",
       " 'flüsternde mumie',\n",
       " 'gespensterschloß',\n",
       " 'seltsame wecker',\n",
       " 'lachende schatten',\n",
       " 'bergmonster',\n",
       " 'rasende löwe',\n",
       " 'zauberspiegel',\n",
       " 'gefährliche erbschaft',\n",
       " 'geisterinsel',\n",
       " 'teufelberg',\n",
       " 'flammende spur',\n",
       " 'tanzende teufel',\n",
       " 'verschwundene schatz',\n",
       " 'aztekenschwert',\n",
       " 'silberne spinne',\n",
       " 'singende schlange',\n",
       " 'silbermine',\n",
       " 'magische kreis',\n",
       " 'doppelgänger',\n",
       " 'riff haie',\n",
       " 'narbengesicht',\n",
       " 'ameisenmensch',\n",
       " 'bedrohte ranch',\n",
       " 'rote pirat',\n",
       " 'höhlenmensch',\n",
       " 'superwal',\n",
       " 'heimliche hehler',\n",
       " 'unsichtbare gegner',\n",
       " 'perlenvögel',\n",
       " 'automarder',\n",
       " 'volk winde',\n",
       " 'weinende sarg',\n",
       " 'höllische werwolf',\n",
       " 'gestohlene preis',\n",
       " 'gold wikinger',\n",
       " 'schrullige millionär',\n",
       " 'giftige gockel',\n",
       " 'gefährlichen fässer',\n",
       " 'comicdiebe',\n",
       " 'verschwundene filmstar',\n",
       " 'riskante ritt',\n",
       " 'musikpirat',\n",
       " 'automafia',\n",
       " 'gefahr verzug',\n",
       " 'gekaufte spieler',\n",
       " 'angriff computerviren',\n",
       " 'tatort zirkus',\n",
       " 'verrückte maler',\n",
       " 'giftiges wasser',\n",
       " 'dopingmixer',\n",
       " 'rache tiger',\n",
       " 'spuk hotel',\n",
       " 'fußballgangster',\n",
       " 'geisterstadt',\n",
       " 'diamantenschmuggel',\n",
       " 'schattenmänner',\n",
       " 'geheimnis särge',\n",
       " 'schatz bergsee',\n",
       " 'späte rache',\n",
       " 'schüsse dunkel',\n",
       " 'verschwundene segler',\n",
       " 'dreckiger deal',\n",
       " 'poltergeist',\n",
       " 'brennende schwert',\n",
       " 'spur rabe',\n",
       " 'stimme',\n",
       " 'pistenteufel',\n",
       " 'leere grab',\n",
       " 'bann voodoo',\n",
       " 'geheimakte ufo',\n",
       " 'verdeckte foul',\n",
       " 'karte bösen',\n",
       " 'meuterei hoher see',\n",
       " 'musik teufel',\n",
       " 'feuerturm',\n",
       " 'nacht angst',\n",
       " 'wolfsgesicht',\n",
       " 'vampir internet',\n",
       " 'tödliche spur',\n",
       " 'feuerteufel',\n",
       " 'labyrinth götter',\n",
       " 'todflug',\n",
       " 'geisterschiff',\n",
       " 'schwarze monster',\n",
       " 'botschaft geisterhand',\n",
       " 'rote rächer',\n",
       " 'insektenstachel',\n",
       " 'tal schrecken',\n",
       " 'rufmord',\n",
       " 'toteninsel',\n",
       " 'hexenhandy',\n",
       " 'doppelte täuschung',\n",
       " 'erbe meisterdieb',\n",
       " 'gift per email',\n",
       " 'nebelberg',\n",
       " 'mann kopf',\n",
       " 'schatz mönche',\n",
       " 'sieben tore',\n",
       " 'gefährliches quiz',\n",
       " 'panik park',\n",
       " 'höhle grauen',\n",
       " 'schlucht dämon',\n",
       " 'auge drache',\n",
       " 'villa toten',\n",
       " 'tödlichem kurs',\n",
       " 'codename cobra',\n",
       " 'finstere rivale',\n",
       " 'düstere vermächtnis',\n",
       " 'geheime schlüssel',\n",
       " 'schwarze skorpion',\n",
       " 'spur',\n",
       " 'geisterzug',\n",
       " 'fußballfieber',\n",
       " 'geistercanyon',\n",
       " 'feuermond',\n",
       " 'schrecken moor',\n",
       " 'schwarze madonna',\n",
       " 'schatten hollywood',\n",
       " 'sms grab',\n",
       " 'fluch drache',\n",
       " 'haus schrecken',\n",
       " 'spuk netz',\n",
       " 'fels dämon',\n",
       " 'tote mönch',\n",
       " 'fluch pirat',\n",
       " 'versunkene dorf',\n",
       " 'pfad angst',\n",
       " 'geheime treppe',\n",
       " 'geheimnis diva',\n",
       " 'stadt vampir',\n",
       " 'fußballfalle',\n",
       " 'tödliches eis',\n",
       " 'poker hölle',\n",
       " 'zwillinge finsternis',\n",
       " 'rache samurai',\n",
       " 'biss bestie',\n",
       " 'grusel campbell castle',\n",
       " 'feurige flut',\n",
       " 'namenlose gegner',\n",
       " 'geisterbucht',\n",
       " 'schwarze sonne',\n",
       " 'skateboardfieber',\n",
       " 'fußballphantom',\n",
       " 'botschaft unterwelt',\n",
       " 'meister tod',\n",
       " 'netz drache',\n",
       " 'zeichen schlange',\n",
       " 'feuergeist',\n",
       " 'nacht tiger',\n",
       " 'geheimnisvolle botschaft',\n",
       " 'blutenden bilder',\n",
       " 'schreiende nebel',\n",
       " 'verschollene pilot',\n",
       " 'fußballteufel',\n",
       " 'schatten giganten',\n",
       " 'brennende stadt',\n",
       " 'blaue biest',\n",
       " 'gps  gangster',\n",
       " 'spur spieler',\n",
       " 'straße grauen',\n",
       " 'phantom meer',\n",
       " 'eisenmann',\n",
       " 'dämon rache',\n",
       " 'tuch toten',\n",
       " 'schattenwelt',\n",
       " 'gestohlene sieg',\n",
       " 'geist goldgräber',\n",
       " 'gefiederte schrecken',\n",
       " 'rache untote',\n",
       " 'flüsternden puppe',\n",
       " 'kabinett zauberer',\n",
       " 'haus henker',\n",
       " 'letzte song',\n",
       " 'hexengarten',\n",
       " 'mann auge',\n",
       " 'insel vergessen',\n",
       " 'silberne amulett',\n",
       " 'signale jenseits',\n",
       " 'unsichtbare passagier',\n",
       " 'kammer rätsel',\n",
       " 'verbrechen',\n",
       " 'bann drache',\n",
       " 'schrecken tiefe',\n",
       " 'zeitreisende',\n",
       " 'reich ungeheuer',\n",
       " 'geheimnis bauchredner',\n",
       " 'auge sturm',\n",
       " 'legende gaukler',\n",
       " 'grüne kobold',\n",
       " 'feuriges auge',\n",
       " 'höhenangst',\n",
       " 'weiße grab',\n",
       " 'tauchgang ungewisse',\n",
       " 'dunkle wächter',\n",
       " 'rätselhafte erbe',\n",
       " 'mottenmann']"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = title_no_stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['superpapagei',\n",
       " 'phantomsee',\n",
       " 'karpatenhund',\n",
       " 'schwarze',\n",
       " 'katze',\n",
       " 'fluch',\n",
       " 'rubin',\n",
       " 'sprechend',\n",
       " 'totenkopf',\n",
       " 'unheimlich',\n",
       " 'drache',\n",
       " 'grüne',\n",
       " 'geist',\n",
       " 'rätselhaft',\n",
       " 'bilder',\n",
       " 'flüsternd',\n",
       " 'mumie',\n",
       " 'gespensterschloß',\n",
       " 'seltsam',\n",
       " 'wecker',\n",
       " 'lachend',\n",
       " 'schatten',\n",
       " 'bergmonster',\n",
       " 'rasend',\n",
       " 'löwe',\n",
       " 'zauberspiegel',\n",
       " 'gefährlich',\n",
       " 'erbschaft',\n",
       " 'geisterinsel',\n",
       " 'teufelberg',\n",
       " 'flammend',\n",
       " 'spur',\n",
       " 'tanzend',\n",
       " 'teufel',\n",
       " 'verschwunden',\n",
       " 'schatz',\n",
       " 'aztekenschwert',\n",
       " 'silberne',\n",
       " 'spinne',\n",
       " 'singend',\n",
       " 'schlange',\n",
       " 'silbermine',\n",
       " 'magische',\n",
       " 'kreis',\n",
       " 'doppelgänger',\n",
       " 'riff',\n",
       " 'haie',\n",
       " 'narbengesicht',\n",
       " 'ameisenmensch',\n",
       " 'bedrohen',\n",
       " 'ranch',\n",
       " 'rote',\n",
       " 'pirat',\n",
       " 'höhlenmensch',\n",
       " 'superwal',\n",
       " 'heimlich',\n",
       " 'hehler',\n",
       " 'unsichtbar',\n",
       " 'gegner',\n",
       " 'perlenvögel',\n",
       " 'automarder',\n",
       " 'volk',\n",
       " 'winde',\n",
       " 'weinend',\n",
       " 'sarg',\n",
       " 'höllische',\n",
       " 'werwolf',\n",
       " 'gestohlen',\n",
       " 'preis',\n",
       " 'gold',\n",
       " 'wikinger',\n",
       " 'schrullig',\n",
       " 'millionär',\n",
       " 'giftig',\n",
       " 'gockel',\n",
       " 'gefährlich',\n",
       " 'fässer',\n",
       " 'comicdiebe',\n",
       " 'verschwunden',\n",
       " 'filmstar',\n",
       " 'riskante',\n",
       " 'ritt',\n",
       " 'musikpirat',\n",
       " 'automafia',\n",
       " 'gefahr',\n",
       " 'verzug',\n",
       " 'gekauft',\n",
       " 'spieler',\n",
       " 'angreifen',\n",
       " 'computerviren',\n",
       " 'tatort',\n",
       " 'zirkus',\n",
       " 'verrücken',\n",
       " 'maler',\n",
       " 'giftig',\n",
       " 'wasser',\n",
       " 'dopingmixer',\n",
       " 'rache',\n",
       " 'tiger',\n",
       " 'spuk',\n",
       " 'hotel',\n",
       " 'fußballgangster',\n",
       " 'geisterstadt',\n",
       " 'diamantenschmuggel',\n",
       " 'schattenmänner',\n",
       " 'geheimnis',\n",
       " 'särge',\n",
       " 'schatz',\n",
       " 'bergsee',\n",
       " 'spät',\n",
       " 'rache',\n",
       " 'schüsse',\n",
       " 'dunkeln',\n",
       " 'verschwunden',\n",
       " 'segler',\n",
       " 'dreckig',\n",
       " 'deal',\n",
       " 'poltergeist',\n",
       " 'brennend',\n",
       " 'schwert',\n",
       " 'spur',\n",
       " 'rabe',\n",
       " 'stimme',\n",
       " 'pistenteufel',\n",
       " 'leer',\n",
       " 'grab',\n",
       " 'bann',\n",
       " 'voodoo',\n",
       " 'geheimakte',\n",
       " 'ufo',\n",
       " 'verdecken',\n",
       " 'foul',\n",
       " 'karte',\n",
       " 'böse',\n",
       " 'meuterei',\n",
       " 'hoch',\n",
       " 'see',\n",
       " 'musik',\n",
       " 'teufel',\n",
       " 'feuerturm',\n",
       " 'nacht',\n",
       " 'angst',\n",
       " 'wolfsgesicht',\n",
       " 'vampir',\n",
       " 'internet',\n",
       " 'tödlich',\n",
       " 'spur',\n",
       " 'feuerteufel',\n",
       " 'labyrinth',\n",
       " 'götter',\n",
       " 'todflug',\n",
       " 'geisterschiff',\n",
       " 'schwarze',\n",
       " 'monster',\n",
       " 'botschaft',\n",
       " 'geisterhand',\n",
       " 'rote',\n",
       " 'rächer',\n",
       " 'insektenstachel',\n",
       " 'tal',\n",
       " 'schrecken',\n",
       " 'rufmord',\n",
       " 'toteninsel',\n",
       " 'hexenhandy',\n",
       " 'doppeln',\n",
       " 'täuschung',\n",
       " 'erben',\n",
       " 'meisterdieb',\n",
       " 'gift',\n",
       " 'per',\n",
       " 'email',\n",
       " 'nebelberg',\n",
       " 'mann',\n",
       " 'kopf',\n",
       " 'schatz',\n",
       " 'mönche',\n",
       " 'sieben',\n",
       " 'tore',\n",
       " 'gefährlich',\n",
       " 'quiz',\n",
       " 'panik',\n",
       " 'park',\n",
       " 'höhle',\n",
       " 'grau',\n",
       " 'schlucht',\n",
       " 'dämon',\n",
       " 'auge',\n",
       " 'drache',\n",
       " 'villa',\n",
       " 'tot',\n",
       " 'tödlich',\n",
       " 'kurs',\n",
       " 'codename',\n",
       " 'cobra',\n",
       " 'finstere',\n",
       " 'rivale',\n",
       " 'düster',\n",
       " 'vermächtnis',\n",
       " 'geheime',\n",
       " 'schlüssel',\n",
       " 'schwarze',\n",
       " 'skorpion',\n",
       " 'spur',\n",
       " 'geisterzug',\n",
       " 'fußballfieber',\n",
       " 'geistercanyon',\n",
       " 'feuermond',\n",
       " 'schrecken',\n",
       " 'moor',\n",
       " 'schwarze',\n",
       " 'madonna',\n",
       " 'schatten',\n",
       " 'hollywood',\n",
       " 'sms',\n",
       " 'grab',\n",
       " 'fluch',\n",
       " 'drache',\n",
       " 'haus',\n",
       " 'schrecken',\n",
       " 'spuk',\n",
       " 'netz',\n",
       " 'fels',\n",
       " 'dämon',\n",
       " 'tot',\n",
       " 'mönch',\n",
       " 'fluch',\n",
       " 'pirat',\n",
       " 'versunken',\n",
       " 'dorf',\n",
       " 'pfad',\n",
       " 'angst',\n",
       " 'geheime',\n",
       " 'treppe',\n",
       " 'geheimnis',\n",
       " 'diva',\n",
       " 'stadt',\n",
       " 'vampir',\n",
       " 'fußballfalle',\n",
       " 'tödlich',\n",
       " 'eis',\n",
       " 'poker',\n",
       " 'hölle',\n",
       " 'zwillinge',\n",
       " 'finsternis',\n",
       " 'rache',\n",
       " 'samurai',\n",
       " 'biss',\n",
       " 'bestie',\n",
       " 'grusel',\n",
       " 'campbell',\n",
       " 'castle',\n",
       " 'feurige',\n",
       " 'flut',\n",
       " 'namenlose',\n",
       " 'gegner',\n",
       " 'geisterbucht',\n",
       " 'schwarze',\n",
       " 'sonne',\n",
       " 'skateboardfieber',\n",
       " 'fußballphantom',\n",
       " 'botschaft',\n",
       " 'unterwelt',\n",
       " 'meistern',\n",
       " 'tod',\n",
       " 'netz',\n",
       " 'drache',\n",
       " 'zeichen',\n",
       " 'schlange',\n",
       " 'feuergeist',\n",
       " 'nacht',\n",
       " 'tiger',\n",
       " 'geheimnisvolle',\n",
       " 'botschaft',\n",
       " 'blutend',\n",
       " 'bilder',\n",
       " 'schreiend',\n",
       " 'nebel',\n",
       " 'verschollen',\n",
       " 'pilot',\n",
       " 'fußballteufel',\n",
       " 'schatten',\n",
       " 'giganten',\n",
       " 'brennend',\n",
       " 'stadt',\n",
       " 'blau',\n",
       " 'biest',\n",
       " 'gps',\n",
       " ' ',\n",
       " 'gangster',\n",
       " 'spur',\n",
       " 'spieler',\n",
       " 'straße',\n",
       " 'grau',\n",
       " 'phantom',\n",
       " 'meer',\n",
       " 'eisenmann',\n",
       " 'dämon',\n",
       " 'rache',\n",
       " 'tuch',\n",
       " 'tot',\n",
       " 'schattenwelt',\n",
       " 'gestohlen',\n",
       " 'sieg',\n",
       " 'geist',\n",
       " 'goldgräber',\n",
       " 'gefiedert',\n",
       " 'schrecken',\n",
       " 'rache',\n",
       " 'untote',\n",
       " 'flüsternd',\n",
       " 'puppe',\n",
       " 'kabinett',\n",
       " 'zauberer',\n",
       " 'haus',\n",
       " 'henker',\n",
       " 'letzte',\n",
       " 'song',\n",
       " 'hexengarten',\n",
       " 'mann',\n",
       " 'auge',\n",
       " 'insel',\n",
       " 'vergessen',\n",
       " 'silberne',\n",
       " 'amulett',\n",
       " 'signale',\n",
       " 'jenseits',\n",
       " 'unsichtbar',\n",
       " 'passagier',\n",
       " 'kammer',\n",
       " 'rätsel',\n",
       " 'verbrechen',\n",
       " 'bann',\n",
       " 'drache',\n",
       " 'schrecken',\n",
       " 'tiefe',\n",
       " 'zeitreisende',\n",
       " 'reichen',\n",
       " 'ungeheuer',\n",
       " 'geheimnis',\n",
       " 'bauchredner',\n",
       " 'auge',\n",
       " 'sturm',\n",
       " 'legend',\n",
       " 'gaukler',\n",
       " 'grüne',\n",
       " 'kobold',\n",
       " 'feurig',\n",
       " 'auge',\n",
       " 'höhenangst',\n",
       " 'weiße',\n",
       " 'grab',\n",
       " 'tauchgang',\n",
       " 'ungewiß',\n",
       " 'dunkel',\n",
       " 'wächter',\n",
       " 'rätselhaft',\n",
       " 'erben',\n",
       " 'mottenmann']"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titles_lemmatised"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'superpapagei phantomsee karpatenhund'"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titles_one_string[:36]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lisa.hornung\\Anaconda2\\envs\\py3_dreif\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Token.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
      "  import sys\n",
      "C:\\Users\\lisa.hornung\\Anaconda2\\envs\\py3_dreif\\lib\\site-packages\\ipykernel_launcher.py:8: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Token.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('gefährliche', 'gestohlene', 0.85386014),\n",
       " ('teufel', 'pistenteufel', 0.8574693),\n",
       " ('verschwundene', 'tödliche', 0.8520479),\n",
       " ('rote', 'tote', 0.8504193),\n",
       " ('gestohlene', 'gefährliche', 0.85386014),\n",
       " ('gestohlene', 'gefährliches', 0.8725113),\n",
       " ('giftige', 'gestohlene', 0.858411),\n",
       " ('pistenteufel', 'teufel', 0.8574693),\n",
       " ('tödliche', 'verschwundene', 0.8520479),\n",
       " ('tödliche', 'rache', 0.8602149),\n",
       " ('tödliche', 'rache', 0.85529023),\n",
       " ('gefährliches', 'gestohlene', 0.8725113),\n",
       " ('gefährliches', 'gestohlene', 0.862969),\n",
       " ('tote', 'rote', 0.8504193),\n",
       " ('rache', 'tödliche', 0.8602149),\n",
       " ('rache', 'tödliche', 0.85529023),\n",
       " ('gestohlene', 'giftige', 0.858411),\n",
       " ('gestohlene', 'gefährliches', 0.862969)]"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_similarity = nlp(titles_one_string)\n",
    "\n",
    "similarities = []\n",
    "\n",
    "for word1 in word_similarity:\n",
    "    for word2 in word_similarity:\n",
    "        if (word1.similarity(word2) > 0.85) and (word1.text != word2.text):\n",
    "            x = word1.text, word2.text, word1.similarity(word2)\n",
    "            similarities.append(x)\n",
    "        \n",
    "similarities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standardising"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      Der neueste Auftrag an die drei Detektive hört...\n",
       "1      Welches Geheimnis verbirgt sich in einem vergi...\n",
       "2      \"Bei mir spukt es!\" Mit diesem verzweifelten A...\n",
       "3      In einem kleinen Wanderzirkus wittern die drei...\n",
       "4      Alfred Hitchcock und die drei Detektive (Firme...\n",
       "                             ...                        \n",
       "201    So hatten sich die drei Detektive ihre Auszeit...\n",
       "202    Ein Kindermädchen, das nachts in Gestalt eines...\n",
       "203    Eigentlich sollte Bob in dem einsam gelegenen ...\n",
       "204    Ein merkwürdiger Anruf erreicht Die Drei Frage...\n",
       "205    In Rocky Beach taucht eine schaurige Gestalt a...\n",
       "Name: content, Length: 206, dtype: object"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# list of acronyms to be replaced\n",
    "replace_dict = {\"\" : \"\"}\n",
    "\n",
    "## make content lower case\n",
    "title = content[\"content\"].str.lower()\n",
    "\n",
    "# replace values within titles\n",
    "\n",
    "# function to loop through the column and replace substrings\n",
    "def replace_values(text, dic):\n",
    "    for x, y in dic.items():\n",
    "        text = text.str.replace(x, y, regex=True)\n",
    "    return text\n",
    "\n",
    "# list of values to be replaced, including punctuation\n",
    "replace_dict = {\"[!\\\"#$%&()*+,./:;<=>?@[\\]^_`{|}~“”-]\": \"\"}\n",
    "\n",
    "\n",
    "# apply function\n",
    "title = replace_values(title, replace_dict)\n",
    "\n",
    "# strip white space at the end\n",
    "title = title.str.strip()\n",
    "\n",
    "title"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3_dreif",
   "language": "python",
   "name": "py3_dreif"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "231.133px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
