{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Three investigators - part I.I\n",
    "\n",
    "A project for scraping and analysing data from a fan site on the audio book called '[The three investigators](https://en.wikipedia.org/wiki/Three_Investigators#Germany)'\n",
    "\n",
    "Part I.I: Topic modelling\n",
    "\n",
    "Using the content and title for each episode to detect the overall topic.\n",
    "\n",
    "\n",
    "**Resources:** \n",
    "\n",
    "- Text mining webinar code on [github](https://github.com/DiarmuidM/text-mining/blob/master/code/tm-extraction-2020-06-16.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.7.5\n"
     ]
    }
   ],
   "source": [
    "#python version used for this project\n",
    "from platform import python_version\n",
    "print(python_version())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\lisa.hornung\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# import modules [as specified in requirements.txt]\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spacy\n",
    "import de_core_news_sm #imports German model from spaCy\n",
    "import nltk\n",
    "import re\n",
    "\n",
    "# download German stop words\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('german'))\n",
    "\n",
    "# To count words in list\n",
    "from collections import Counter\n",
    "\n",
    "# for file \n",
    "import os\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#change directory to root folder\n",
    "os.chdir(\"..\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load scraped datafiles\n",
    "meta = pd.read_csv(\".\\\\data\\\\scraped\\\\meta.csv\")\n",
    "content = pd.read_csv(\".\\\\data\\\\scraped\\\\content_all.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Title"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standardising"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0            Der Super-Papagei (Hörspiel)\n",
       "1               Der Phantomsee (Hörspiel)\n",
       "2             Der Karpatenhund (Hörspiel)\n",
       "3           Die schwarze Katze (Hörspiel)\n",
       "4         Der Fluch des Rubins (Hörspiel)\n",
       "                      ...                \n",
       "200             Das weiße Grab (Hörspiel)\n",
       "201    Tauchgang ins Ungewisse (Hörspiel)\n",
       "202         Der dunkle Wächter (Hörspiel)\n",
       "203       Das rätselhafte Erbe (Hörspiel)\n",
       "204      ...und der Mottenmann (Hörspiel)\n",
       "Name: titel, Length: 205, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta[\"titel\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0             der superpapagei\n",
       "1               der phantomsee\n",
       "2             der karpatenhund\n",
       "3           die schwarze katze\n",
       "4          der fluch des rubin\n",
       "                ...           \n",
       "200             das weiße grab\n",
       "201    tauchgang ins ungewisse\n",
       "202         der dunkle wächter\n",
       "203       das rätselhafte erbe\n",
       "204         und der mottenmann\n",
       "Name: titel, Length: 205, dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## make titles lower case\n",
    "title = meta[\"titel\"].str.lower()\n",
    "\n",
    "# replace values within titles\n",
    "\n",
    "# function to loop through the column and replace substrings\n",
    "def replace_values(text, dic):\n",
    "    for x, y in dic.items():\n",
    "        text = text.str.replace(x, y, regex=True)\n",
    "    return text\n",
    "\n",
    "# list of values to be replaced, including punctuation\n",
    "replace_dict = {\"hörspiel\": \"\", \n",
    "                \"[!\\\"#$%&()*+,./:;<=>?@[\\]^_`{|}~“”-]\": \"\",\n",
    "                \n",
    "                #list of noun forms /adjectives that the German lemmitizer doesn't pick up\n",
    "                \"tigers\": \"tiger\",\n",
    "                \"fouls\":\"foul\",\n",
    "                \"teufels\":\"teufel\",\n",
    "                \"schreckens\":\"schrecken\",\n",
    "                \"meisterdiebs\":\"meisterdieb\",\n",
    "                \"grauens\":\"grauen\",\n",
    "                \"todes\":\"tod\",\n",
    "                \"spielers\":\"spieler\",\n",
    "                u\"goldgräbers\" :u\"goldgräber\"  ,\n",
    "                \"zauberers\":\"zauberer\",\n",
    "                \"henkers\":\"henker\",\n",
    "                \"vergessens\" :\"vergessen\",\n",
    "                \"bauchredners\" :\"bauchredner\",\n",
    "                \"sturms\" : \"sturm\",\n",
    "                \"rubins\":\"rubin\",\n",
    "                r\"feurige\\b\" : \"feurig\",\n",
    "               \n",
    "                #change plural to singular and remove gendered forms\n",
    "                \"musikpiraten\" : \"musikpirat\",\n",
    "                \"seglerin\" : \"segler\",\n",
    "                \"stimmen\" : \"stimme\",\n",
    "                \"karten\":\"karte\",\n",
    "                u\"dämonen\": u\"dämon\",\n",
    "                \"drachen\":\"drache\",\n",
    "                \"piraten\":\"pirat\",\n",
    "                \"botschaften\": \"botschaft\",\n",
    "                \"raben\":\"rabe\",\n",
    "                \"schlangen\":\"schlange\",\n",
    "                \"untoten\":\"untote\",\n",
    "                \"puppen\":\"puppe\",\n",
    "                \"augen\" : \"auge\",\n",
    "                \"vampire\":\"vampir\",\n",
    "               u\"mönche\" :u\"mönch\"}\n",
    "                \n",
    "# apply function\n",
    "title = replace_values(title, replace_dict)\n",
    "\n",
    "# strip white space at the end\n",
    "title = title.str.strip()\n",
    "\n",
    "title"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### remove stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['superpapagei',\n",
       " 'phantomsee',\n",
       " 'karpatenhund',\n",
       " 'schwarze katze',\n",
       " 'fluch rubin',\n",
       " 'sprechende totenkopf',\n",
       " 'unheimliche drache',\n",
       " 'grüne geist',\n",
       " 'rätselhaften bilder',\n",
       " 'flüsternde mumie']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# split titles into substrings using space as delimiter\n",
    "title_split = title.str.split(\" \")\n",
    "\n",
    "# create empty list to store titles without stop words\n",
    "title_no_stop_words = []\n",
    "\n",
    "# iterate through each word in each title and append those that are no stop words\n",
    "for words in title_split:\n",
    "    x = []\n",
    "    for word in words:\n",
    "        if word not in stop_words:\n",
    "            x.append(word)\n",
    "    title_no_stop_words.append(x)\n",
    "\n",
    "# join titles back together\n",
    "title_no_stop_words = [\" \".join(items) for items in title_no_stop_words]\n",
    "title_no_stop_words[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### lemmatise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['superpapagei',\n",
       " 'phantomsee',\n",
       " 'karpatenhund',\n",
       " 'schwarze',\n",
       " 'katze',\n",
       " 'fluch',\n",
       " 'rubin',\n",
       " 'sprechend',\n",
       " 'totenkopf',\n",
       " 'unheimlich']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## merge titles into one string\n",
    "titles_one_string =  ' '.join(title_no_stop_words)\n",
    "\n",
    "# load German model from SpaCy\n",
    "nlp = de_core_news_sm.load()\n",
    "\n",
    "# create new list to store lemmatised titles\n",
    "titles_lemmatised = []\n",
    "\n",
    "# iterate through titles as one string and store the lemmatised words in new list\n",
    "for title in nlp(titles_one_string):\n",
    "    x = title.lemma_\n",
    "    titles_lemmatised.append(x)\n",
    "\n",
    "titles_lemmatised[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized: superpapagei | Lemma: superpapagei\n",
      "Tokenized: phantomsee | Lemma: phantomsee\n",
      "Tokenized: karpatenhund | Lemma: karpatenhund\n",
      "Tokenized: schwarze | Lemma: schwarze\n",
      "Tokenized: katze | Lemma: katze\n",
      "Tokenized: fluch | Lemma: fluch\n",
      "Tokenized: rubin | Lemma: rubin\n",
      "Tokenized: sprechende | Lemma: sprechend\n",
      "Tokenized: totenkopf | Lemma: totenkopf\n",
      "Tokenized: unheimliche | Lemma: unheimlich\n",
      "Tokenized: drache | Lemma: drache\n",
      "Tokenized: grüne | Lemma: grüne\n",
      "Tokenized: geist | Lemma: geist\n",
      "Tokenized: rätselhaften | Lemma: rätselhaft\n",
      "Tokenized: bilder | Lemma: bilder\n",
      "Tokenized: flüsternde | Lemma: flüsternd\n",
      "Tokenized: mumie | Lemma: mumie\n",
      "Tokenized: gespensterschloß | Lemma: gespensterschloß\n",
      "Tokenized: seltsame | Lemma: seltsam\n",
      "Tokenized: wecker | Lemma: wecker\n",
      "Tokenized: lachende | Lemma: lachend\n",
      "Tokenized: schatten | Lemma: schatten\n",
      "Tokenized: bergmonster | Lemma: bergmonster\n",
      "Tokenized: rasende | Lemma: rasend\n",
      "Tokenized: löwe | Lemma: löwe\n",
      "Tokenized: zauberspiegel | Lemma: zauberspiegel\n",
      "Tokenized: gefährliche | Lemma: gefährlich\n",
      "Tokenized: erbschaft | Lemma: erbschaft\n",
      "Tokenized: geisterinsel | Lemma: geisterinsel\n",
      "Tokenized: teufelberg | Lemma: teufelberg\n",
      "Tokenized: flammende | Lemma: flammend\n",
      "Tokenized: spur | Lemma: spur\n",
      "Tokenized: tanzende | Lemma: tanzend\n",
      "Tokenized: teufel | Lemma: teufel\n",
      "Tokenized: verschwundene | Lemma: verschwunden\n",
      "Tokenized: schatz | Lemma: schatz\n",
      "Tokenized: aztekenschwert | Lemma: aztekenschwert\n",
      "Tokenized: silberne | Lemma: silberne\n",
      "Tokenized: spinne | Lemma: spinne\n",
      "Tokenized: singende | Lemma: singend\n",
      "Tokenized: schlange | Lemma: schlange\n",
      "Tokenized: silbermine | Lemma: silbermine\n",
      "Tokenized: magische | Lemma: magische\n",
      "Tokenized: kreis | Lemma: kreis\n",
      "Tokenized: doppelgänger | Lemma: doppelgänger\n",
      "Tokenized: riff | Lemma: riff\n",
      "Tokenized: haie | Lemma: haie\n",
      "Tokenized: narbengesicht | Lemma: narbengesicht\n",
      "Tokenized: ameisenmensch | Lemma: ameisenmensch\n",
      "Tokenized: bedrohte | Lemma: bedrohen\n",
      "Tokenized: ranch | Lemma: ranch\n",
      "Tokenized: rote | Lemma: rote\n",
      "Tokenized: pirat | Lemma: pirat\n",
      "Tokenized: höhlenmensch | Lemma: höhlenmensch\n",
      "Tokenized: superwal | Lemma: superwal\n",
      "Tokenized: heimliche | Lemma: heimlich\n",
      "Tokenized: hehler | Lemma: hehler\n",
      "Tokenized: unsichtbare | Lemma: unsichtbar\n",
      "Tokenized: gegner | Lemma: gegner\n",
      "Tokenized: perlenvögel | Lemma: perlenvögel\n",
      "Tokenized: automarder | Lemma: automarder\n",
      "Tokenized: volk | Lemma: volk\n",
      "Tokenized: winde | Lemma: winde\n",
      "Tokenized: weinende | Lemma: weinend\n",
      "Tokenized: sarg | Lemma: sarg\n",
      "Tokenized: höllische | Lemma: höllische\n",
      "Tokenized: werwolf | Lemma: werwolf\n",
      "Tokenized: gestohlene | Lemma: gestohlen\n",
      "Tokenized: preis | Lemma: preis\n",
      "Tokenized: gold | Lemma: gold\n",
      "Tokenized: wikinger | Lemma: wikinger\n",
      "Tokenized: schrullige | Lemma: schrullig\n",
      "Tokenized: millionär | Lemma: millionär\n",
      "Tokenized: giftige | Lemma: giftig\n",
      "Tokenized: gockel | Lemma: gockel\n",
      "Tokenized: gefährlichen | Lemma: gefährlich\n",
      "Tokenized: fässer | Lemma: fässer\n",
      "Tokenized: comicdiebe | Lemma: comicdiebe\n",
      "Tokenized: verschwundene | Lemma: verschwunden\n",
      "Tokenized: filmstar | Lemma: filmstar\n",
      "Tokenized: riskante | Lemma: riskante\n",
      "Tokenized: ritt | Lemma: ritt\n",
      "Tokenized: musikpirat | Lemma: musikpirat\n",
      "Tokenized: automafia | Lemma: automafia\n",
      "Tokenized: gefahr | Lemma: gefahr\n",
      "Tokenized: verzug | Lemma: verzug\n",
      "Tokenized: gekaufte | Lemma: gekauft\n",
      "Tokenized: spieler | Lemma: spieler\n",
      "Tokenized: angriff | Lemma: angreifen\n",
      "Tokenized: computerviren | Lemma: computerviren\n",
      "Tokenized: tatort | Lemma: tatort\n",
      "Tokenized: zirkus | Lemma: zirkus\n",
      "Tokenized: verrückte | Lemma: verrücken\n",
      "Tokenized: maler | Lemma: maler\n",
      "Tokenized: giftiges | Lemma: giftig\n",
      "Tokenized: wasser | Lemma: wasser\n",
      "Tokenized: dopingmixer | Lemma: dopingmixer\n",
      "Tokenized: rache | Lemma: rache\n",
      "Tokenized: tiger | Lemma: tiger\n",
      "Tokenized: spuk | Lemma: spuk\n",
      "Tokenized: hotel | Lemma: hotel\n",
      "Tokenized: fußballgangster | Lemma: fußballgangster\n",
      "Tokenized: geisterstadt | Lemma: geisterstadt\n",
      "Tokenized: diamantenschmuggel | Lemma: diamantenschmuggel\n",
      "Tokenized: schattenmänner | Lemma: schattenmänner\n",
      "Tokenized: geheimnis | Lemma: geheimnis\n",
      "Tokenized: särge | Lemma: särge\n",
      "Tokenized: schatz | Lemma: schatz\n",
      "Tokenized: bergsee | Lemma: bergsee\n",
      "Tokenized: späte | Lemma: spät\n",
      "Tokenized: rache | Lemma: rache\n",
      "Tokenized: schüsse | Lemma: schüsse\n",
      "Tokenized: dunkel | Lemma: dunkeln\n",
      "Tokenized: verschwundene | Lemma: verschwunden\n",
      "Tokenized: segler | Lemma: segler\n",
      "Tokenized: dreckiger | Lemma: dreckig\n",
      "Tokenized: deal | Lemma: deal\n",
      "Tokenized: poltergeist | Lemma: poltergeist\n",
      "Tokenized: brennende | Lemma: brennend\n",
      "Tokenized: schwert | Lemma: schwert\n",
      "Tokenized: spur | Lemma: spur\n",
      "Tokenized: rabe | Lemma: rabe\n",
      "Tokenized: stimme | Lemma: stimme\n",
      "Tokenized: pistenteufel | Lemma: pistenteufel\n",
      "Tokenized: leere | Lemma: leer\n",
      "Tokenized: grab | Lemma: grab\n",
      "Tokenized: bann | Lemma: bann\n",
      "Tokenized: voodoo | Lemma: voodoo\n",
      "Tokenized: geheimakte | Lemma: geheimakte\n",
      "Tokenized: ufo | Lemma: ufo\n",
      "Tokenized: verdeckte | Lemma: verdecken\n",
      "Tokenized: foul | Lemma: foul\n",
      "Tokenized: karte | Lemma: karte\n",
      "Tokenized: bösen | Lemma: böse\n",
      "Tokenized: meuterei | Lemma: meuterei\n",
      "Tokenized: hoher | Lemma: hoch\n",
      "Tokenized: see | Lemma: see\n",
      "Tokenized: musik | Lemma: musik\n",
      "Tokenized: teufel | Lemma: teufel\n",
      "Tokenized: feuerturm | Lemma: feuerturm\n",
      "Tokenized: nacht | Lemma: nacht\n",
      "Tokenized: angst | Lemma: angst\n",
      "Tokenized: wolfsgesicht | Lemma: wolfsgesicht\n",
      "Tokenized: vampir | Lemma: vampir\n",
      "Tokenized: internet | Lemma: internet\n",
      "Tokenized: tödliche | Lemma: tödlich\n",
      "Tokenized: spur | Lemma: spur\n",
      "Tokenized: feuerteufel | Lemma: feuerteufel\n",
      "Tokenized: labyrinth | Lemma: labyrinth\n",
      "Tokenized: götter | Lemma: götter\n",
      "Tokenized: todflug | Lemma: todflug\n",
      "Tokenized: geisterschiff | Lemma: geisterschiff\n",
      "Tokenized: schwarze | Lemma: schwarze\n",
      "Tokenized: monster | Lemma: monster\n",
      "Tokenized: botschaft | Lemma: botschaft\n",
      "Tokenized: geisterhand | Lemma: geisterhand\n",
      "Tokenized: rote | Lemma: rote\n",
      "Tokenized: rächer | Lemma: rächer\n",
      "Tokenized: insektenstachel | Lemma: insektenstachel\n",
      "Tokenized: tal | Lemma: tal\n",
      "Tokenized: schrecken | Lemma: schrecken\n",
      "Tokenized: rufmord | Lemma: rufmord\n",
      "Tokenized: toteninsel | Lemma: toteninsel\n",
      "Tokenized: hexenhandy | Lemma: hexenhandy\n",
      "Tokenized: doppelte | Lemma: doppeln\n",
      "Tokenized: täuschung | Lemma: täuschung\n",
      "Tokenized: erbe | Lemma: erben\n",
      "Tokenized: meisterdieb | Lemma: meisterdieb\n",
      "Tokenized: gift | Lemma: gift\n",
      "Tokenized: per | Lemma: per\n",
      "Tokenized: email | Lemma: email\n",
      "Tokenized: nebelberg | Lemma: nebelberg\n",
      "Tokenized: mann | Lemma: mann\n",
      "Tokenized: kopf | Lemma: kopf\n",
      "Tokenized: schatz | Lemma: schatz\n",
      "Tokenized: mönch | Lemma: mönch\n",
      "Tokenized: sieben | Lemma: sieben\n",
      "Tokenized: tore | Lemma: tore\n",
      "Tokenized: gefährliches | Lemma: gefährlich\n",
      "Tokenized: quiz | Lemma: quiz\n",
      "Tokenized: panik | Lemma: panik\n",
      "Tokenized: park | Lemma: park\n",
      "Tokenized: höhle | Lemma: höhle\n",
      "Tokenized: grauen | Lemma: grau\n",
      "Tokenized: schlucht | Lemma: schlucht\n",
      "Tokenized: dämon | Lemma: dämon\n",
      "Tokenized: auge | Lemma: auge\n",
      "Tokenized: drache | Lemma: drache\n",
      "Tokenized: villa | Lemma: villa\n",
      "Tokenized: toten | Lemma: tot\n",
      "Tokenized: tödlichem | Lemma: tödlich\n",
      "Tokenized: kurs | Lemma: kurs\n",
      "Tokenized: codename | Lemma: codename\n",
      "Tokenized: cobra | Lemma: cobra\n",
      "Tokenized: finstere | Lemma: finstere\n",
      "Tokenized: rivale | Lemma: rivale\n",
      "Tokenized: düstere | Lemma: düster\n",
      "Tokenized: vermächtnis | Lemma: vermächtnis\n",
      "Tokenized: geheime | Lemma: geheime\n",
      "Tokenized: schlüssel | Lemma: schlüssel\n",
      "Tokenized: schwarze | Lemma: schwarze\n",
      "Tokenized: skorpion | Lemma: skorpion\n",
      "Tokenized: spur | Lemma: spur\n",
      "Tokenized: geisterzug | Lemma: geisterzug\n",
      "Tokenized: fußballfieber | Lemma: fußballfieber\n",
      "Tokenized: geistercanyon | Lemma: geistercanyon\n",
      "Tokenized: feuermond | Lemma: feuermond\n",
      "Tokenized: schrecken | Lemma: schrecken\n",
      "Tokenized: moor | Lemma: moor\n",
      "Tokenized: schwarze | Lemma: schwarze\n",
      "Tokenized: madonna | Lemma: madonna\n",
      "Tokenized: schatten | Lemma: schatten\n",
      "Tokenized: hollywood | Lemma: hollywood\n",
      "Tokenized: sms | Lemma: sms\n",
      "Tokenized: grab | Lemma: grab\n",
      "Tokenized: fluch | Lemma: fluch\n",
      "Tokenized: drache | Lemma: drache\n",
      "Tokenized: haus | Lemma: haus\n",
      "Tokenized: schrecken | Lemma: schrecken\n",
      "Tokenized: spuk | Lemma: spuk\n",
      "Tokenized: netz | Lemma: netz\n",
      "Tokenized: fels | Lemma: fels\n",
      "Tokenized: dämon | Lemma: dämon\n",
      "Tokenized: tote | Lemma: tot\n",
      "Tokenized: mönch | Lemma: mönch\n",
      "Tokenized: fluch | Lemma: fluch\n",
      "Tokenized: pirat | Lemma: pirat\n",
      "Tokenized: versunkene | Lemma: versunken\n",
      "Tokenized: dorf | Lemma: dorf\n",
      "Tokenized: pfad | Lemma: pfad\n",
      "Tokenized: angst | Lemma: angst\n",
      "Tokenized: geheime | Lemma: geheime\n",
      "Tokenized: treppe | Lemma: treppe\n",
      "Tokenized: geheimnis | Lemma: geheimnis\n",
      "Tokenized: diva | Lemma: diva\n",
      "Tokenized: stadt | Lemma: stadt\n",
      "Tokenized: vampir | Lemma: vampir\n",
      "Tokenized: fußballfalle | Lemma: fußballfalle\n",
      "Tokenized: tödliches | Lemma: tödlich\n",
      "Tokenized: eis | Lemma: eis\n",
      "Tokenized: poker | Lemma: poker\n",
      "Tokenized: hölle | Lemma: hölle\n",
      "Tokenized: zwillinge | Lemma: zwillinge\n",
      "Tokenized: finsternis | Lemma: finsternis\n",
      "Tokenized: rache | Lemma: rache\n",
      "Tokenized: samurai | Lemma: samurai\n",
      "Tokenized: biss | Lemma: biss\n",
      "Tokenized: bestie | Lemma: bestie\n",
      "Tokenized: grusel | Lemma: grusel\n",
      "Tokenized: campbell | Lemma: campbell\n",
      "Tokenized: castle | Lemma: castle\n",
      "Tokenized: feurig | Lemma: feurig\n",
      "Tokenized: flut | Lemma: flut\n",
      "Tokenized: namenlose | Lemma: namenlose\n",
      "Tokenized: gegner | Lemma: gegner\n",
      "Tokenized: geisterbucht | Lemma: geisterbucht\n",
      "Tokenized: schwarze | Lemma: schwarze\n",
      "Tokenized: sonne | Lemma: sonne\n",
      "Tokenized: skateboardfieber | Lemma: skateboardfieber\n",
      "Tokenized: fußballphantom | Lemma: fußballphantom\n",
      "Tokenized: botschaft | Lemma: botschaft\n",
      "Tokenized: unterwelt | Lemma: unterwelt\n",
      "Tokenized: meister | Lemma: meistern\n",
      "Tokenized: tod | Lemma: tod\n",
      "Tokenized: netz | Lemma: netz\n",
      "Tokenized: drache | Lemma: drache\n",
      "Tokenized: zeichen | Lemma: zeichen\n",
      "Tokenized: schlange | Lemma: schlange\n",
      "Tokenized: feuergeist | Lemma: feuergeist\n",
      "Tokenized: nacht | Lemma: nacht\n",
      "Tokenized: tiger | Lemma: tiger\n",
      "Tokenized: geheimnisvolle | Lemma: geheimnisvolle\n",
      "Tokenized: botschaft | Lemma: botschaft\n",
      "Tokenized: blutenden | Lemma: blutend\n",
      "Tokenized: bilder | Lemma: bilder\n",
      "Tokenized: schreiende | Lemma: schreiend\n",
      "Tokenized: nebel | Lemma: nebel\n",
      "Tokenized: verschollene | Lemma: verschollen\n",
      "Tokenized: pilot | Lemma: pilot\n",
      "Tokenized: fußballteufel | Lemma: fußballteufel\n",
      "Tokenized: schatten | Lemma: schatten\n",
      "Tokenized: giganten | Lemma: giganten\n",
      "Tokenized: brennende | Lemma: brennend\n",
      "Tokenized: stadt | Lemma: stadt\n",
      "Tokenized: blaue | Lemma: blau\n",
      "Tokenized: biest | Lemma: biest\n",
      "Tokenized: gps | Lemma: gps\n",
      "Tokenized:   | Lemma:  \n",
      "Tokenized: gangster | Lemma: gangster\n",
      "Tokenized: spur | Lemma: spur\n",
      "Tokenized: spieler | Lemma: spieler\n",
      "Tokenized: straße | Lemma: straße\n",
      "Tokenized: grauen | Lemma: grau\n",
      "Tokenized: phantom | Lemma: phantom\n",
      "Tokenized: meer | Lemma: meer\n",
      "Tokenized: eisenmann | Lemma: eisenmann\n",
      "Tokenized: dämon | Lemma: dämon\n",
      "Tokenized: rache | Lemma: rache\n",
      "Tokenized: tuch | Lemma: tuch\n",
      "Tokenized: toten | Lemma: tot\n",
      "Tokenized: schattenwelt | Lemma: schattenwelt\n",
      "Tokenized: gestohlene | Lemma: gestohlen\n",
      "Tokenized: sieg | Lemma: sieg\n",
      "Tokenized: geist | Lemma: geist\n",
      "Tokenized: goldgräber | Lemma: goldgräber\n",
      "Tokenized: gefiederte | Lemma: gefiedert\n",
      "Tokenized: schrecken | Lemma: schrecken\n",
      "Tokenized: rache | Lemma: rache\n",
      "Tokenized: untote | Lemma: untote\n",
      "Tokenized: flüsternden | Lemma: flüsternd\n",
      "Tokenized: puppe | Lemma: puppe\n",
      "Tokenized: kabinett | Lemma: kabinett\n",
      "Tokenized: zauberer | Lemma: zauberer\n",
      "Tokenized: haus | Lemma: haus\n",
      "Tokenized: henker | Lemma: henker\n",
      "Tokenized: letzte | Lemma: letzte\n",
      "Tokenized: song | Lemma: song\n",
      "Tokenized: hexengarten | Lemma: hexengarten\n",
      "Tokenized: mann | Lemma: mann\n",
      "Tokenized: auge | Lemma: auge\n",
      "Tokenized: insel | Lemma: insel\n",
      "Tokenized: vergessen | Lemma: vergessen\n",
      "Tokenized: silberne | Lemma: silberne\n",
      "Tokenized: amulett | Lemma: amulett\n",
      "Tokenized: signale | Lemma: signale\n",
      "Tokenized: jenseits | Lemma: jenseits\n",
      "Tokenized: unsichtbare | Lemma: unsichtbar\n",
      "Tokenized: passagier | Lemma: passagier\n",
      "Tokenized: kammer | Lemma: kammer\n",
      "Tokenized: rätsel | Lemma: rätsel\n",
      "Tokenized: verbrechen | Lemma: verbrechen\n",
      "Tokenized: bann | Lemma: bann\n",
      "Tokenized: drache | Lemma: drache\n",
      "Tokenized: schrecken | Lemma: schrecken\n",
      "Tokenized: tiefe | Lemma: tiefe\n",
      "Tokenized: zeitreisende | Lemma: zeitreisende\n",
      "Tokenized: reich | Lemma: reichen\n",
      "Tokenized: ungeheuer | Lemma: ungeheuer\n",
      "Tokenized: geheimnis | Lemma: geheimnis\n",
      "Tokenized: bauchredner | Lemma: bauchredner\n",
      "Tokenized: auge | Lemma: auge\n",
      "Tokenized: sturm | Lemma: sturm\n",
      "Tokenized: legende | Lemma: legend\n",
      "Tokenized: gaukler | Lemma: gaukler\n",
      "Tokenized: grüne | Lemma: grüne\n",
      "Tokenized: kobold | Lemma: kobold\n",
      "Tokenized: feuriges | Lemma: feurig\n",
      "Tokenized: auge | Lemma: auge\n",
      "Tokenized: höhenangst | Lemma: höhenangst\n",
      "Tokenized: weiße | Lemma: weiße\n",
      "Tokenized: grab | Lemma: grab\n",
      "Tokenized: tauchgang | Lemma: tauchgang\n",
      "Tokenized: ungewisse | Lemma: ungewiß\n",
      "Tokenized: dunkle | Lemma: dunkel\n",
      "Tokenized: wächter | Lemma: wächter\n",
      "Tokenized: rätselhafte | Lemma: rätselhaft\n",
      "Tokenized: erbe | Lemma: erben\n",
      "Tokenized: mottenmann | Lemma: mottenmann\n"
     ]
    }
   ],
   "source": [
    "## Check how words have been lemmatised to explore potential issues\n",
    "words = str(titles_one_string)\n",
    "\n",
    "for word in nlp.tokenizer(words):\n",
    "    print(\"Tokenized: %s | Lemma: %s\" %(word, word.lemma_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Counting words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>schrecken</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>rache</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>schwarze</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>spur</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>drache</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>rabe</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>stimme</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>pistenteufel</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>leer</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>mottenmann</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>282 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            index  0\n",
       "149     schrecken  5\n",
       "94          rache  5\n",
       "3        schwarze  5\n",
       "31           spur  5\n",
       "10         drache  5\n",
       "..            ... ..\n",
       "114          rabe  1\n",
       "115        stimme  1\n",
       "116  pistenteufel  1\n",
       "117          leer  1\n",
       "281    mottenmann  1\n",
       "\n",
       "[282 rows x 2 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# count frequencies of words\n",
    "counts = Counter(titles_lemmatised)\n",
    "counts = pd.DataFrame.from_dict(counts, orient='index').reset_index() #make into dataframe\n",
    "counts = counts.sort_values(by=counts.columns[1], ascending=False) #sort by frequency\n",
    "\n",
    "#save output\n",
    "counts.to_csv(\".\\\\data\\\\processed\\\\title_word_count.csv\", encoding='utf8', index=False)\n",
    "\n",
    "counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# categories \n",
    "cat_dict = {'colour': [r'grün' , r'schw[aä]rz', r'gelb', r'blau', r'(^|abend|dunkel|hell)rot', r'weiß'],\n",
    "           'animal' : [r'katze', r'hund', r'löwe', r'papagei', r'spinne', r'schlange', r'wal', r'wolf',\n",
    "                      r'tiger', r'rabe', r'insekt', r'cobra', r'skorpion', r'motte', r'vögel', r'marder'\n",
    "                     r'ameise', r'hai', 'gockel'],\n",
    "           'sport': ['spieler', 'fussball', 'fußball', 'skateboard', 'poker', 'quiz', 'foul'],\n",
    "           'paranormal' : ['drache', 'monster', 'geist', 'phantom', 'teufel', 'werwolf', 'spuk', 'vodoo', 'vampir',\n",
    "                       'dämon', 'fluch',  'untote', 'hexe', 'kobold', 'biest', 'ungeheuer',\n",
    "                       'jenseits', 'hölle','höllisch', 'unterwelt', 'ufo', 'magisch'],\n",
    "           'place' : ['stadt', 'meer', 'see', 'straße', 'bucht', 'castle', 'dorf', 'fels', 'hollywood',\n",
    "                        'canyon', 'villa', 'höhle', 'schlucht', 'berg','insel', 'turm', 'zirkus', 'ranch',\n",
    "                    'riff','schloß' , 'mine', 'tal', 'moor', 'haus'],\n",
    "            'tech' : ['computer', 'internet', 'email', 'sms', 'netz', 'gps', 'handy'],\n",
    "            'death' : ['tot', 'grab','tod', 'tödlich', 'mumie', 'särge'],\n",
    "            'mystery': ['rätsel', 'geheimnis', 'verschwunden', 'unsichtbar', 'verschollen', 'täuschung', 'heimlich'],\n",
    "            'person' : ['diva', 'mönch',  'madonna', 'pilot', 'zauberer', 'bauchredner','hehler',\n",
    "                     'gaukler', 'wächter', 'mann', 'passagier', 'segler', 'maler', 'filmstar', 'millionär'],\n",
    "            'ethnic' : ['volk', 'wikinger', 'azteke', 'pirat','samurai'],\n",
    "           'fire': [\"feuer\", \"brennen\", \"flamme\"],\n",
    "           'danger' : [\"gefahr\", \"schrecken\", r\"gefährlich\", \"grauen\"],\n",
    "           'treasure': [\"gold\", \"diamant\", 'schatz', 'rubin']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['grün', 'schw[aä]rz', 'gelb', 'blau', '(^|abend|dunkel|hell)rot', 'weiß']\n",
      "['katze', 'hund', 'löwe', 'papagei', 'spinne', 'schlange', 'wal', 'wolf', 'tiger', 'rabe', 'insekt', 'cobra', 'skorpion', 'motte', 'vögel', 'marderameise', 'hai', 'gockel']\n",
      "['spieler', 'fussball', 'fußball', 'skateboard', 'poker', 'quiz', 'foul']\n",
      "['drache', 'monster', 'geist', 'phantom', 'teufel', 'werwolf', 'spuk', 'vodoo', 'vampir', 'dämon', 'fluch', 'untote', 'hexe', 'kobold', 'biest', 'ungeheuer', 'jenseits', 'hölle', 'höllisch', 'unterwelt', 'ufo', 'magisch']\n",
      "['stadt', 'meer', 'see', 'straße', 'bucht', 'castle', 'dorf', 'fels', 'hollywood', 'canyon', 'villa', 'höhle', 'schlucht', 'berg', 'insel', 'turm', 'zirkus', 'ranch', 'riff', 'schloß', 'mine', 'tal', 'moor', 'haus']\n",
      "['computer', 'internet', 'email', 'sms', 'netz', 'gps', 'handy']\n",
      "['tot', 'grab', 'tod', 'tödlich', 'mumie', 'särge']\n",
      "['rätsel', 'geheimnis', 'verschwunden', 'unsichtbar', 'verschollen', 'täuschung', 'heimlich']\n",
      "['diva', 'mönch', 'madonna', 'pilot', 'zauberer', 'bauchredner', 'hehler', 'gaukler', 'wächter', 'mann', 'passagier', 'segler', 'maler', 'filmstar', 'millionär']\n",
      "['volk', 'wikinger', 'azteke', 'pirat', 'samurai']\n",
      "['feuer', 'brennen', 'flamme']\n",
      "['gefahr', 'schrecken', 'gefährlich', 'grauen']\n",
      "['gold', 'diamant', 'schatz', 'rubin']\n"
     ]
    }
   ],
   "source": [
    "for key in cat_dict:\n",
    "    print(cat_dict[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title_clean</th>\n",
       "      <th>title_colour</th>\n",
       "      <th>title_animal</th>\n",
       "      <th>title_sport</th>\n",
       "      <th>title_paranormal</th>\n",
       "      <th>title_place</th>\n",
       "      <th>title_tech</th>\n",
       "      <th>title_death</th>\n",
       "      <th>title_mystery</th>\n",
       "      <th>title_person</th>\n",
       "      <th>title_ethnic</th>\n",
       "      <th>title_fire</th>\n",
       "      <th>title_danger</th>\n",
       "      <th>title_treasure</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>superpapagei</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>phantomsee</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>karpatenhund</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>schwarze katze</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fluch rubin</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      title_clean  title_colour  title_animal  title_sport  title_paranormal  \\\n",
       "0    superpapagei           0.0           1.0          0.0               0.0   \n",
       "1      phantomsee           0.0           0.0          0.0               1.0   \n",
       "2    karpatenhund           0.0           1.0          0.0               0.0   \n",
       "3  schwarze katze           1.0           1.0          0.0               0.0   \n",
       "4     fluch rubin           0.0           0.0          0.0               1.0   \n",
       "\n",
       "   title_place  title_tech  title_death  title_mystery  title_person  \\\n",
       "0          0.0         0.0          0.0            0.0           0.0   \n",
       "1          1.0         0.0          0.0            0.0           0.0   \n",
       "2          0.0         0.0          0.0            0.0           0.0   \n",
       "3          0.0         0.0          0.0            0.0           0.0   \n",
       "4          0.0         0.0          0.0            0.0           0.0   \n",
       "\n",
       "   title_ethnic  title_fire  title_danger  title_treasure  id  \n",
       "0           0.0         0.0           0.0             0.0   1  \n",
       "1           0.0         0.0           0.0             0.0   2  \n",
       "2           0.0         0.0           0.0             0.0   3  \n",
       "3           0.0         0.0           0.0             0.0   4  \n",
       "4           0.0         0.0           0.0             1.0   5  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create dataframe with title_no_stop_words\n",
    "df_title = pd.DataFrame(title_no_stop_words, columns=[\"title_clean\"])\n",
    "\n",
    "# iterate through dictionary. If contains word, put 1 into the column for that category\n",
    "for key in cat_dict:\n",
    "    for values in cat_dict[key]:\n",
    "        df_title.loc[df_title[\"title_clean\"].str.contains(values), key] = 1  \n",
    "        \n",
    "for keys in cat_dict.keys():\n",
    "    df_title[keys].fillna(0, inplace=True)\n",
    "    df_title = df_title.rename(columns={keys: \"title_\" + keys})\n",
    "\n",
    "# merge id from meta data based on index\n",
    "df_title = df_title.merge(meta[\"id\"],how=\"left\", left_index=True, right_index=True)\n",
    "\n",
    "# save output\n",
    "df_title.to_csv(\".\\\\data\\\\processed\\\\title_categories.csv\", encoding='utf8', index=False)\n",
    "\n",
    "df_title.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "title_paranormal    48.0\n",
       "title_place         36.0\n",
       "title_animal        20.0\n",
       "title_person        19.0\n",
       "title_mystery       16.0\n",
       "title_death         16.0\n",
       "title_danger        11.0\n",
       "title_sport         11.0\n",
       "title_colour        11.0\n",
       "title_tech           8.0\n",
       "title_treasure       7.0\n",
       "title_fire           7.0\n",
       "title_ethnic         7.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# count themes\n",
    "themes = df_title[df_title.columns[1:-1]].sum().sort_values(ascending=False)\n",
    "\n",
    "# save output\n",
    "themes.to_csv(\".\\\\data\\\\processed\\\\title_categories_agg.csv\", encoding='utf8', header=False)\n",
    "\n",
    "themes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word similarity\n",
    "\n",
    "Exploratory - didn't reveal too much, probably limited due to being in German and models not too great."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'superpapagei phantomsee karpatenhund'"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titles_one_string[:36]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lisa.hornung\\Anaconda2\\envs\\py3_dreif\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Token.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
      "  import sys\n",
      "C:\\Users\\lisa.hornung\\Anaconda2\\envs\\py3_dreif\\lib\\site-packages\\ipykernel_launcher.py:8: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Token.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('gefährliche', 'gestohlene', 0.85386014),\n",
       " ('teufel', 'pistenteufel', 0.8574693),\n",
       " ('verschwundene', 'tödliche', 0.8520479),\n",
       " ('rote', 'tote', 0.8504193),\n",
       " ('gestohlene', 'gefährliche', 0.85386014),\n",
       " ('gestohlene', 'gefährliches', 0.8725113),\n",
       " ('giftige', 'gestohlene', 0.858411),\n",
       " ('pistenteufel', 'teufel', 0.8574693),\n",
       " ('tödliche', 'verschwundene', 0.8520479),\n",
       " ('tödliche', 'rache', 0.8602149),\n",
       " ('tödliche', 'rache', 0.85529023),\n",
       " ('gefährliches', 'gestohlene', 0.8725113),\n",
       " ('gefährliches', 'gestohlene', 0.862969),\n",
       " ('tote', 'rote', 0.8504193),\n",
       " ('rache', 'tödliche', 0.8602149),\n",
       " ('rache', 'tödliche', 0.85529023),\n",
       " ('gestohlene', 'giftige', 0.858411),\n",
       " ('gestohlene', 'gefährliches', 0.862969)]"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_similarity = nlp(titles_one_string)\n",
    "\n",
    "similarities = []\n",
    "\n",
    "for word1 in word_similarity:\n",
    "    for word2 in word_similarity:\n",
    "        if (word1.similarity(word2) > 0.85) and (word1.text != word2.text):\n",
    "            x = word1.text, word2.text, word1.similarity(word2)\n",
    "            similarities.append(x)\n",
    "        \n",
    "similarities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Content - tbc\n",
    "\n",
    "Focussed on title analysis. This could be another potential route for analysis but requires a bit more work. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standardising"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      Der neueste Auftrag an die drei Detektive hört...\n",
       "1      Welches Geheimnis verbirgt sich in einem vergi...\n",
       "2      \"Bei mir spukt es!\" Mit diesem verzweifelten A...\n",
       "3      In einem kleinen Wanderzirkus wittern die drei...\n",
       "4      Alfred Hitchcock und die drei Detektive (Firme...\n",
       "                             ...                        \n",
       "201    So hatten sich die drei Detektive ihre Auszeit...\n",
       "202    Ein Kindermädchen, das nachts in Gestalt eines...\n",
       "203    Eigentlich sollte Bob in dem einsam gelegenen ...\n",
       "204    Ein merkwürdiger Anruf erreicht Die Drei Frage...\n",
       "205    In Rocky Beach taucht eine schaurige Gestalt a...\n",
       "Name: content, Length: 206, dtype: object"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# list of acronyms to be replaced\n",
    "replace_dict = {\"\" : \"\"}\n",
    "\n",
    "## make content lower case\n",
    "title = content[\"content\"].str.lower()\n",
    "\n",
    "# replace values within titles\n",
    "\n",
    "# function to loop through the column and replace substrings\n",
    "def replace_values(text, dic):\n",
    "    for x, y in dic.items():\n",
    "        text = text.str.replace(x, y, regex=True)\n",
    "    return text\n",
    "\n",
    "# list of values to be replaced, including punctuation\n",
    "replace_dict = {\"[!\\\"#$%&()*+,./:;<=>?@[\\]^_`{|}~“”-]\": \"\"}\n",
    "\n",
    "\n",
    "# apply function\n",
    "title = replace_values(title, replace_dict)\n",
    "\n",
    "# strip white space at the end\n",
    "title = title.str.strip()\n",
    "\n",
    "title"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3_dreif",
   "language": "python",
   "name": "py3_dreif"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "231.133px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
